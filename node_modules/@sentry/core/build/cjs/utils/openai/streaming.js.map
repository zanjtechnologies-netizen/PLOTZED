{"version":3,"file":"streaming.js","sources":["../../../../src/utils/openai/streaming.ts"],"sourcesContent":["import { captureException } from '../../exports';\nimport { SPAN_STATUS_ERROR } from '../../tracing';\nimport type { Span } from '../../types-hoist/span';\nimport {\n  GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE,\n  GEN_AI_RESPONSE_STREAMING_ATTRIBUTE,\n  GEN_AI_RESPONSE_TEXT_ATTRIBUTE,\n  GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport { RESPONSE_EVENT_TYPES } from './constants';\nimport type { OpenAIResponseObject } from './types';\nimport {\n  type ChatCompletionChunk,\n  type ChatCompletionToolCall,\n  type ResponseFunctionCall,\n  type ResponseStreamingEvent,\n} from './types';\nimport {\n  isChatCompletionChunk,\n  isResponsesApiStreamEvent,\n  setCommonResponseAttributes,\n  setTokenUsageAttributes,\n} from './utils';\n\n/**\n * State object used to accumulate information from a stream of OpenAI events/chunks.\n */\ninterface StreamingState {\n  /** Types of events encountered in the stream. */\n  eventTypes: string[];\n  /** Collected response text fragments (for output recording). */\n  responseTexts: string[];\n  /** Reasons for finishing the response, as reported by the API. */\n  finishReasons: string[];\n  /** The response ID. */\n  responseId: string;\n  /** The model name. */\n  responseModel: string;\n  /** The timestamp of the response. */\n  responseTimestamp: number;\n  /** Number of prompt/input tokens used. */\n  promptTokens: number | undefined;\n  /** Number of completion/output tokens used. */\n  completionTokens: number | undefined;\n  /** Total number of tokens used (prompt + completion). */\n  totalTokens: number | undefined;\n  /**\n   * Accumulated tool calls from Chat Completion streaming, indexed by tool call index.\n   * @see https://platform.openai.com/docs/guides/function-calling?api-mode=chat#streaming\n   */\n  chatCompletionToolCalls: Record<number, ChatCompletionToolCall>;\n  /**\n   * Accumulated function calls from Responses API streaming.\n   * @see https://platform.openai.com/docs/guides/function-calling?api-mode=responses#streaming\n   */\n  responsesApiToolCalls: Array<ResponseFunctionCall | unknown>;\n}\n\n/**\n * Processes tool calls from a chat completion chunk delta.\n * Follows the pattern: accumulate by index, then convert to array at the end.\n *\n * @param toolCalls - Array of tool calls from the delta.\n * @param state - The current streaming state to update.\n *\n *  @see https://platform.openai.com/docs/guides/function-calling#streaming\n */\nfunction processChatCompletionToolCalls(toolCalls: ChatCompletionToolCall[], state: StreamingState): void {\n  for (const toolCall of toolCalls) {\n    const index = toolCall.index;\n    if (index === undefined || !toolCall.function) continue;\n\n    // Initialize tool call if this is the first chunk for this index\n    if (!(index in state.chatCompletionToolCalls)) {\n      state.chatCompletionToolCalls[index] = {\n        ...toolCall,\n        function: {\n          name: toolCall.function.name,\n          arguments: toolCall.function.arguments || '',\n        },\n      };\n    } else {\n      // Accumulate function arguments from subsequent chunks\n      const existingToolCall = state.chatCompletionToolCalls[index];\n      if (toolCall.function.arguments && existingToolCall?.function) {\n        existingToolCall.function.arguments += toolCall.function.arguments;\n      }\n    }\n  }\n}\n\n/**\n * Processes a single OpenAI ChatCompletionChunk event, updating the streaming state.\n *\n * @param chunk - The ChatCompletionChunk event to process.\n * @param state - The current streaming state to update.\n * @param recordOutputs - Whether to record output text fragments.\n */\nfunction processChatCompletionChunk(chunk: ChatCompletionChunk, state: StreamingState, recordOutputs: boolean): void {\n  state.responseId = chunk.id ?? state.responseId;\n  state.responseModel = chunk.model ?? state.responseModel;\n  state.responseTimestamp = chunk.created ?? state.responseTimestamp;\n\n  if (chunk.usage) {\n    // For stream responses, the input tokens remain constant across all events in the stream.\n    // Output tokens, however, are only finalized in the last event.\n    // Since we can't guarantee that the last event will include usage data or even be a typed event,\n    // we update the output token values on every event that includes them.\n    // This ensures that output token usage is always set, even if the final event lacks it.\n    state.promptTokens = chunk.usage.prompt_tokens;\n    state.completionTokens = chunk.usage.completion_tokens;\n    state.totalTokens = chunk.usage.total_tokens;\n  }\n\n  for (const choice of chunk.choices ?? []) {\n    if (recordOutputs) {\n      if (choice.delta?.content) {\n        state.responseTexts.push(choice.delta.content);\n      }\n\n      // Handle tool calls from delta\n      if (choice.delta?.tool_calls) {\n        processChatCompletionToolCalls(choice.delta.tool_calls, state);\n      }\n    }\n    if (choice.finish_reason) {\n      state.finishReasons.push(choice.finish_reason);\n    }\n  }\n}\n\n/**\n * Processes a single OpenAI Responses API streaming event, updating the streaming state and span.\n *\n * @param streamEvent - The event to process (may be an error or unknown object).\n * @param state - The current streaming state to update.\n * @param recordOutputs - Whether to record output text fragments.\n * @param span - The span to update with error status if needed.\n */\nfunction processResponsesApiEvent(\n  streamEvent: ResponseStreamingEvent | unknown | Error,\n  state: StreamingState,\n  recordOutputs: boolean,\n  span: Span,\n): void {\n  if (!(streamEvent && typeof streamEvent === 'object')) {\n    state.eventTypes.push('unknown:non-object');\n    return;\n  }\n  if (streamEvent instanceof Error) {\n    span.setStatus({ code: SPAN_STATUS_ERROR, message: 'internal_error' });\n    captureException(streamEvent, {\n      mechanism: {\n        handled: false,\n        type: 'auto.ai.openai.stream-response',\n      },\n    });\n    return;\n  }\n\n  if (!('type' in streamEvent)) return;\n  const event = streamEvent as ResponseStreamingEvent;\n\n  if (!RESPONSE_EVENT_TYPES.includes(event.type)) {\n    state.eventTypes.push(event.type);\n    return;\n  }\n\n  // Handle output text delta\n  if (recordOutputs) {\n    // Handle tool call events for Responses API\n    if (event.type === 'response.output_item.done' && 'item' in event) {\n      state.responsesApiToolCalls.push(event.item);\n    }\n\n    if (event.type === 'response.output_text.delta' && 'delta' in event && event.delta) {\n      state.responseTexts.push(event.delta);\n      return;\n    }\n  }\n\n  if ('response' in event) {\n    const { response } = event as { response: OpenAIResponseObject };\n    state.responseId = response.id ?? state.responseId;\n    state.responseModel = response.model ?? state.responseModel;\n    state.responseTimestamp = response.created_at ?? state.responseTimestamp;\n\n    if (response.usage) {\n      // For stream responses, the input tokens remain constant across all events in the stream.\n      // Output tokens, however, are only finalized in the last event.\n      // Since we can't guarantee that the last event will include usage data or even be a typed event,\n      // we update the output token values on every event that includes them.\n      // This ensures that output token usage is always set, even if the final event lacks it.\n      state.promptTokens = response.usage.input_tokens;\n      state.completionTokens = response.usage.output_tokens;\n      state.totalTokens = response.usage.total_tokens;\n    }\n\n    if (response.status) {\n      state.finishReasons.push(response.status);\n    }\n\n    if (recordOutputs && response.output_text) {\n      state.responseTexts.push(response.output_text);\n    }\n  }\n}\n\n/**\n * Instruments a stream of OpenAI events, updating the provided span with relevant attributes and\n * optionally recording output text. This function yields each event from the input stream as it is processed.\n *\n * @template T - The type of events in the stream.\n * @param stream - The async iterable stream of events to instrument.\n * @param span - The span to add attributes to and to finish at the end of the stream.\n * @param recordOutputs - Whether to record output text fragments in the span.\n * @returns An async generator yielding each event from the input stream.\n */\nexport async function* instrumentStream<T>(\n  stream: AsyncIterable<T>,\n  span: Span,\n  recordOutputs: boolean,\n): AsyncGenerator<T, void, unknown> {\n  const state: StreamingState = {\n    eventTypes: [],\n    responseTexts: [],\n    finishReasons: [],\n    responseId: '',\n    responseModel: '',\n    responseTimestamp: 0,\n    promptTokens: undefined,\n    completionTokens: undefined,\n    totalTokens: undefined,\n    chatCompletionToolCalls: {},\n    responsesApiToolCalls: [],\n  };\n\n  try {\n    for await (const event of stream) {\n      if (isChatCompletionChunk(event)) {\n        processChatCompletionChunk(event as ChatCompletionChunk, state, recordOutputs);\n      } else if (isResponsesApiStreamEvent(event)) {\n        processResponsesApiEvent(event as ResponseStreamingEvent, state, recordOutputs, span);\n      }\n      yield event;\n    }\n  } finally {\n    setCommonResponseAttributes(span, state.responseId, state.responseModel, state.responseTimestamp);\n    setTokenUsageAttributes(span, state.promptTokens, state.completionTokens, state.totalTokens);\n\n    span.setAttributes({\n      [GEN_AI_RESPONSE_STREAMING_ATTRIBUTE]: true,\n    });\n\n    if (state.finishReasons.length) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE]: JSON.stringify(state.finishReasons),\n      });\n    }\n\n    if (recordOutputs && state.responseTexts.length) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TEXT_ATTRIBUTE]: state.responseTexts.join(''),\n      });\n    }\n\n    // Set tool calls attribute if any were accumulated\n    const chatCompletionToolCallsArray = Object.values(state.chatCompletionToolCalls);\n    const allToolCalls = [...chatCompletionToolCallsArray, ...state.responsesApiToolCalls];\n\n    if (allToolCalls.length > 0) {\n      span.setAttributes({\n        [GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE]: JSON.stringify(allToolCalls),\n      });\n    }\n\n    span.end();\n  }\n}\n"],"names":["SPAN_STATUS_ERROR","captureException","RESPONSE_EVENT_TYPES","isChatCompletionChunk","isResponsesApiStreamEvent","setCommonResponseAttributes","setTokenUsageAttributes","GEN_AI_RESPONSE_STREAMING_ATTRIBUTE","GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE","GEN_AI_RESPONSE_TEXT_ATTRIBUTE","GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE"],"mappings":";;;;;;;;AAwBA;AACA;AACA;;AAgCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,8BAA8B,CAAC,SAAS,EAA4B,KAAK,EAAwB;AAC1G,EAAE,KAAK,MAAM,QAAA,IAAY,SAAS,EAAE;AACpC,IAAI,MAAM,KAAA,GAAQ,QAAQ,CAAC,KAAK;AAChC,IAAI,IAAI,KAAA,KAAU,SAAA,IAAa,CAAC,QAAQ,CAAC,QAAQ,EAAE;;AAEnD;AACA,IAAI,IAAI,EAAE,KAAA,IAAS,KAAK,CAAC,uBAAuB,CAAC,EAAE;AACnD,MAAM,KAAK,CAAC,uBAAuB,CAAC,KAAK,IAAI;AAC7C,QAAQ,GAAG,QAAQ;AACnB,QAAQ,QAAQ,EAAE;AAClB,UAAU,IAAI,EAAE,QAAQ,CAAC,QAAQ,CAAC,IAAI;AACtC,UAAU,SAAS,EAAE,QAAQ,CAAC,QAAQ,CAAC,SAAA,IAAa,EAAE;AACtD,SAAS;AACT,OAAO;AACP,WAAW;AACX;AACA,MAAM,MAAM,mBAAmB,KAAK,CAAC,uBAAuB,CAAC,KAAK,CAAC;AACnE,MAAM,IAAI,QAAQ,CAAC,QAAQ,CAAC,SAAA,IAAa,gBAAgB,EAAE,QAAQ,EAAE;AACrE,QAAQ,gBAAgB,CAAC,QAAQ,CAAC,SAAA,IAAa,QAAQ,CAAC,QAAQ,CAAC,SAAS;AAC1E;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,0BAA0B,CAAC,KAAK,EAAuB,KAAK,EAAkB,aAAa,EAAiB;AACrH,EAAE,KAAK,CAAC,UAAA,GAAa,KAAK,CAAC,EAAA,IAAM,KAAK,CAAC,UAAU;AACjD,EAAE,KAAK,CAAC,aAAA,GAAgB,KAAK,CAAC,KAAA,IAAS,KAAK,CAAC,aAAa;AAC1D,EAAE,KAAK,CAAC,iBAAA,GAAoB,KAAK,CAAC,OAAA,IAAW,KAAK,CAAC,iBAAiB;;AAEpE,EAAE,IAAI,KAAK,CAAC,KAAK,EAAE;AACnB;AACA;AACA;AACA;AACA;AACA,IAAI,KAAK,CAAC,YAAA,GAAe,KAAK,CAAC,KAAK,CAAC,aAAa;AAClD,IAAI,KAAK,CAAC,gBAAA,GAAmB,KAAK,CAAC,KAAK,CAAC,iBAAiB;AAC1D,IAAI,KAAK,CAAC,WAAA,GAAc,KAAK,CAAC,KAAK,CAAC,YAAY;AAChD;;AAEA,EAAE,KAAK,MAAM,MAAA,IAAU,KAAK,CAAC,OAAA,IAAW,EAAE,EAAE;AAC5C,IAAI,IAAI,aAAa,EAAE;AACvB,MAAM,IAAI,MAAM,CAAC,KAAK,EAAE,OAAO,EAAE;AACjC,QAAQ,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,OAAO,CAAC;AACtD;;AAEA;AACA,MAAM,IAAI,MAAM,CAAC,KAAK,EAAE,UAAU,EAAE;AACpC,QAAQ,8BAA8B,CAAC,MAAM,CAAC,KAAK,CAAC,UAAU,EAAE,KAAK,CAAC;AACtE;AACA;AACA,IAAI,IAAI,MAAM,CAAC,aAAa,EAAE;AAC9B,MAAM,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC;AACpD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,wBAAwB;AACjC,EAAE,WAAW;AACb,EAAE,KAAK;AACP,EAAE,aAAa;AACf,EAAE,IAAI;AACN,EAAQ;AACR,EAAE,IAAI,EAAE,WAAA,IAAe,OAAO,WAAA,KAAgB,QAAQ,CAAC,EAAE;AACzD,IAAI,KAAK,CAAC,UAAU,CAAC,IAAI,CAAC,oBAAoB,CAAC;AAC/C,IAAI;AACJ;AACA,EAAE,IAAI,WAAA,YAAuB,KAAK,EAAE;AACpC,IAAI,IAAI,CAAC,SAAS,CAAC,EAAE,IAAI,EAAEA,4BAAiB,EAAE,OAAO,EAAE,gBAAA,EAAkB,CAAC;AAC1E,IAAIC,0BAAgB,CAAC,WAAW,EAAE;AAClC,MAAM,SAAS,EAAE;AACjB,QAAQ,OAAO,EAAE,KAAK;AACtB,QAAQ,IAAI,EAAE,gCAAgC;AAC9C,OAAO;AACP,KAAK,CAAC;AACN,IAAI;AACJ;;AAEA,EAAE,IAAI,EAAE,UAAU,WAAW,CAAC,EAAE;AAChC,EAAE,MAAM,KAAA,GAAQ,WAAA;;AAEhB,EAAE,IAAI,CAACC,8BAAoB,CAAC,QAAQ,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE;AAClD,IAAI,KAAK,CAAC,UAAU,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC;AACrC,IAAI;AACJ;;AAEA;AACA,EAAE,IAAI,aAAa,EAAE;AACrB;AACA,IAAI,IAAI,KAAK,CAAC,IAAA,KAAS,2BAAA,IAA+B,MAAA,IAAU,KAAK,EAAE;AACvE,MAAM,KAAK,CAAC,qBAAqB,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC;AAClD;;AAEA,IAAI,IAAI,KAAK,CAAC,SAAS,4BAAA,IAAgC,OAAA,IAAW,KAAA,IAAS,KAAK,CAAC,KAAK,EAAE;AACxF,MAAM,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC;AAC3C,MAAM;AACN;AACA;;AAEA,EAAE,IAAI,UAAA,IAAc,KAAK,EAAE;AAC3B,IAAI,MAAM,EAAE,QAAA,EAAS,GAAI,KAAA;AACzB,IAAI,KAAK,CAAC,UAAA,GAAa,QAAQ,CAAC,EAAA,IAAM,KAAK,CAAC,UAAU;AACtD,IAAI,KAAK,CAAC,aAAA,GAAgB,QAAQ,CAAC,KAAA,IAAS,KAAK,CAAC,aAAa;AAC/D,IAAI,KAAK,CAAC,iBAAA,GAAoB,QAAQ,CAAC,UAAA,IAAc,KAAK,CAAC,iBAAiB;;AAE5E,IAAI,IAAI,QAAQ,CAAC,KAAK,EAAE;AACxB;AACA;AACA;AACA;AACA;AACA,MAAM,KAAK,CAAC,YAAA,GAAe,QAAQ,CAAC,KAAK,CAAC,YAAY;AACtD,MAAM,KAAK,CAAC,gBAAA,GAAmB,QAAQ,CAAC,KAAK,CAAC,aAAa;AAC3D,MAAM,KAAK,CAAC,WAAA,GAAc,QAAQ,CAAC,KAAK,CAAC,YAAY;AACrD;;AAEA,IAAI,IAAI,QAAQ,CAAC,MAAM,EAAE;AACzB,MAAM,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC;AAC/C;;AAEA,IAAI,IAAI,aAAA,IAAiB,QAAQ,CAAC,WAAW,EAAE;AAC/C,MAAM,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC;AACpD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,gBAAgB,gBAAgB;AACvC,EAAE,MAAM;AACR,EAAE,IAAI;AACN,EAAE,aAAa;AACf,EAAoC;AACpC,EAAE,MAAM,KAAK,GAAmB;AAChC,IAAI,UAAU,EAAE,EAAE;AAClB,IAAI,aAAa,EAAE,EAAE;AACrB,IAAI,aAAa,EAAE,EAAE;AACrB,IAAI,UAAU,EAAE,EAAE;AAClB,IAAI,aAAa,EAAE,EAAE;AACrB,IAAI,iBAAiB,EAAE,CAAC;AACxB,IAAI,YAAY,EAAE,SAAS;AAC3B,IAAI,gBAAgB,EAAE,SAAS;AAC/B,IAAI,WAAW,EAAE,SAAS;AAC1B,IAAI,uBAAuB,EAAE,EAAE;AAC/B,IAAI,qBAAqB,EAAE,EAAE;AAC7B,GAAG;;AAEH,EAAE,IAAI;AACN,IAAI,WAAW,MAAM,KAAA,IAAS,MAAM,EAAE;AACtC,MAAM,IAAIC,2BAAqB,CAAC,KAAK,CAAC,EAAE;AACxC,QAAQ,0BAA0B,CAAC,KAAA,GAA8B,KAAK,EAAE,aAAa,CAAC;AACtF,OAAM,MAAO,IAAIC,+BAAyB,CAAC,KAAK,CAAC,EAAE;AACnD,QAAQ,wBAAwB,CAAC,KAAA,GAAiC,KAAK,EAAE,aAAa,EAAE,IAAI,CAAC;AAC7F;AACA,MAAM,MAAM,KAAK;AACjB;AACA,YAAY;AACZ,IAAIC,iCAA2B,CAAC,IAAI,EAAE,KAAK,CAAC,UAAU,EAAE,KAAK,CAAC,aAAa,EAAE,KAAK,CAAC,iBAAiB,CAAC;AACrG,IAAIC,6BAAuB,CAAC,IAAI,EAAE,KAAK,CAAC,YAAY,EAAE,KAAK,CAAC,gBAAgB,EAAE,KAAK,CAAC,WAAW,CAAC;;AAEhG,IAAI,IAAI,CAAC,aAAa,CAAC;AACvB,MAAM,CAACC,mDAAmC,GAAG,IAAI;AACjD,KAAK,CAAC;;AAEN,IAAI,IAAI,KAAK,CAAC,aAAa,CAAC,MAAM,EAAE;AACpC,MAAM,IAAI,CAAC,aAAa,CAAC;AACzB,QAAQ,CAACC,wDAAwC,GAAG,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,aAAa,CAAC;AACvF,OAAO,CAAC;AACR;;AAEA,IAAI,IAAI,aAAA,IAAiB,KAAK,CAAC,aAAa,CAAC,MAAM,EAAE;AACrD,MAAM,IAAI,CAAC,aAAa,CAAC;AACzB,QAAQ,CAACC,8CAA8B,GAAG,KAAK,CAAC,aAAa,CAAC,IAAI,CAAC,EAAE,CAAC;AACtE,OAAO,CAAC;AACR;;AAEA;AACA,IAAI,MAAM,4BAAA,GAA+B,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,uBAAuB,CAAC;AACrF,IAAI,MAAM,YAAA,GAAe,CAAC,GAAG,4BAA4B,EAAE,GAAG,KAAK,CAAC,qBAAqB,CAAC;;AAE1F,IAAI,IAAI,YAAY,CAAC,MAAA,GAAS,CAAC,EAAE;AACjC,MAAM,IAAI,CAAC,aAAa,CAAC;AACzB,QAAQ,CAACC,oDAAoC,GAAG,IAAI,CAAC,SAAS,CAAC,YAAY,CAAC;AAC5E,OAAO,CAAC;AACR;;AAEA,IAAI,IAAI,CAAC,GAAG,EAAE;AACd;AACA;;;;"}