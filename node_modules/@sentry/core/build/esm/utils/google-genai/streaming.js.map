{"version":3,"file":"streaming.js","sources":["../../../../src/utils/google-genai/streaming.ts"],"sourcesContent":["import { captureException } from '../../exports';\nimport { SPAN_STATUS_ERROR } from '../../tracing';\nimport type { Span, SpanAttributeValue } from '../../types-hoist/span';\nimport {\n  GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE,\n  GEN_AI_RESPONSE_ID_ATTRIBUTE,\n  GEN_AI_RESPONSE_MODEL_ATTRIBUTE,\n  GEN_AI_RESPONSE_STREAMING_ATTRIBUTE,\n  GEN_AI_RESPONSE_TEXT_ATTRIBUTE,\n  GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE,\n  GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE,\n  GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE,\n} from '../ai/gen-ai-attributes';\nimport type { GoogleGenAIResponse } from './types';\n\n/**\n * State object used to accumulate information from a stream of Google GenAI events.\n */\ninterface StreamingState {\n  /** Collected response text fragments (for output recording). */\n  responseTexts: string[];\n  /** Reasons for finishing the response, as reported by the API. */\n  finishReasons: string[];\n  /** The response ID. */\n  responseId?: string;\n  /** The model name. */\n  responseModel?: string;\n  /** Number of prompt/input tokens used. */\n  promptTokens?: number;\n  /** Number of completion/output tokens used. */\n  completionTokens?: number;\n  /** Number of total tokens used. */\n  totalTokens?: number;\n  /** Accumulated tool calls (finalized) */\n  toolCalls: Array<Record<string, unknown>>;\n}\n\n/**\n * Checks if a response chunk contains an error\n * @param chunk - The response chunk to check\n * @param span - The span to update if error is found\n * @returns Whether an error occurred\n */\nfunction isErrorChunk(chunk: GoogleGenAIResponse, span: Span): boolean {\n  const feedback = chunk?.promptFeedback;\n  if (feedback?.blockReason) {\n    const message = feedback.blockReasonMessage ?? feedback.blockReason;\n    span.setStatus({ code: SPAN_STATUS_ERROR, message: `Content blocked: ${message}` });\n    captureException(`Content blocked: ${message}`, {\n      mechanism: { handled: false, type: 'auto.ai.google_genai' },\n    });\n    return true;\n  }\n  return false;\n}\n\n/**\n * Processes response metadata from a chunk\n * @param chunk - The response chunk to process\n * @param state - The state of the streaming process\n */\nfunction handleResponseMetadata(chunk: GoogleGenAIResponse, state: StreamingState): void {\n  if (typeof chunk.responseId === 'string') state.responseId = chunk.responseId;\n  if (typeof chunk.modelVersion === 'string') state.responseModel = chunk.modelVersion;\n\n  const usage = chunk.usageMetadata;\n  if (usage) {\n    if (typeof usage.promptTokenCount === 'number') state.promptTokens = usage.promptTokenCount;\n    if (typeof usage.candidatesTokenCount === 'number') state.completionTokens = usage.candidatesTokenCount;\n    if (typeof usage.totalTokenCount === 'number') state.totalTokens = usage.totalTokenCount;\n  }\n}\n\n/**\n * Processes candidate content from a response chunk\n * @param chunk - The response chunk to process\n * @param state - The state of the streaming process\n * @param recordOutputs - Whether to record outputs\n */\nfunction handleCandidateContent(chunk: GoogleGenAIResponse, state: StreamingState, recordOutputs: boolean): void {\n  if (Array.isArray(chunk.functionCalls)) {\n    state.toolCalls.push(...chunk.functionCalls);\n  }\n\n  for (const candidate of chunk.candidates ?? []) {\n    if (candidate?.finishReason && !state.finishReasons.includes(candidate.finishReason)) {\n      state.finishReasons.push(candidate.finishReason);\n    }\n\n    for (const part of candidate?.content?.parts ?? []) {\n      if (recordOutputs && part.text) state.responseTexts.push(part.text);\n      if (part.functionCall) {\n        state.toolCalls.push({\n          type: 'function',\n          id: part.functionCall.id,\n          name: part.functionCall.name,\n          arguments: part.functionCall.args,\n        });\n      }\n    }\n  }\n}\n\n/**\n * Processes a single chunk from the Google GenAI stream\n * @param chunk - The chunk to process\n * @param state - The state of the streaming process\n * @param recordOutputs - Whether to record outputs\n * @param span - The span to update\n */\nfunction processChunk(chunk: GoogleGenAIResponse, state: StreamingState, recordOutputs: boolean, span: Span): void {\n  if (!chunk || isErrorChunk(chunk, span)) return;\n  handleResponseMetadata(chunk, state);\n  handleCandidateContent(chunk, state, recordOutputs);\n}\n\n/**\n * Instruments an async iterable stream of Google GenAI response chunks, updates the span with\n * streaming attributes and (optionally) the aggregated output text, and yields\n * each chunk from the input stream unchanged.\n */\nexport async function* instrumentStream(\n  stream: AsyncIterable<GoogleGenAIResponse>,\n  span: Span,\n  recordOutputs: boolean,\n): AsyncGenerator<GoogleGenAIResponse, void, unknown> {\n  const state: StreamingState = {\n    responseTexts: [],\n    finishReasons: [],\n    toolCalls: [],\n  };\n\n  try {\n    for await (const chunk of stream) {\n      processChunk(chunk, state, recordOutputs, span);\n      yield chunk;\n    }\n  } finally {\n    const attrs: Record<string, SpanAttributeValue> = {\n      [GEN_AI_RESPONSE_STREAMING_ATTRIBUTE]: true,\n    };\n\n    if (state.responseId) attrs[GEN_AI_RESPONSE_ID_ATTRIBUTE] = state.responseId;\n    if (state.responseModel) attrs[GEN_AI_RESPONSE_MODEL_ATTRIBUTE] = state.responseModel;\n    if (state.promptTokens !== undefined) attrs[GEN_AI_USAGE_INPUT_TOKENS_ATTRIBUTE] = state.promptTokens;\n    if (state.completionTokens !== undefined) attrs[GEN_AI_USAGE_OUTPUT_TOKENS_ATTRIBUTE] = state.completionTokens;\n    if (state.totalTokens !== undefined) attrs[GEN_AI_USAGE_TOTAL_TOKENS_ATTRIBUTE] = state.totalTokens;\n\n    if (state.finishReasons.length) {\n      attrs[GEN_AI_RESPONSE_FINISH_REASONS_ATTRIBUTE] = JSON.stringify(state.finishReasons);\n    }\n    if (recordOutputs && state.responseTexts.length) {\n      attrs[GEN_AI_RESPONSE_TEXT_ATTRIBUTE] = state.responseTexts.join('');\n    }\n    if (recordOutputs && state.toolCalls.length) {\n      attrs[GEN_AI_RESPONSE_TOOL_CALLS_ATTRIBUTE] = JSON.stringify(state.toolCalls);\n    }\n\n    span.setAttributes(attrs);\n    span.end();\n  }\n}\n"],"names":[],"mappings":";;;;AAgBA;AACA;AACA;;AAoBA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,YAAY,CAAC,KAAK,EAAuB,IAAI,EAAiB;AACvE,EAAE,MAAM,QAAA,GAAW,KAAK,EAAE,cAAc;AACxC,EAAE,IAAI,QAAQ,EAAE,WAAW,EAAE;AAC7B,IAAI,MAAM,UAAU,QAAQ,CAAC,kBAAA,IAAsB,QAAQ,CAAC,WAAW;AACvE,IAAI,IAAI,CAAC,SAAS,CAAC,EAAE,IAAI,EAAE,iBAAiB,EAAE,OAAO,EAAE,CAAC,iBAAiB,EAAE,OAAO,CAAC,CAAA,EAAA,CAAA;AACA,IAAA,gBAAA,CAAA,CAAA,iBAAA,EAAA,OAAA,CAAA,CAAA,EAAA;AACA,MAAA,SAAA,EAAA,EAAA,OAAA,EAAA,KAAA,EAAA,IAAA,EAAA,sBAAA,EAAA;AACA,KAAA,CAAA;AACA,IAAA,OAAA,IAAA;AACA;AACA,EAAA,OAAA,KAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAA,sBAAA,CAAA,KAAA,EAAA,KAAA,EAAA;AACA,EAAA,IAAA,OAAA,KAAA,CAAA,UAAA,KAAA,QAAA,EAAA,KAAA,CAAA,UAAA,GAAA,KAAA,CAAA,UAAA;AACA,EAAA,IAAA,OAAA,KAAA,CAAA,YAAA,KAAA,QAAA,EAAA,KAAA,CAAA,aAAA,GAAA,KAAA,CAAA,YAAA;;AAEA,EAAA,MAAA,KAAA,GAAA,KAAA,CAAA,aAAA;AACA,EAAA,IAAA,KAAA,EAAA;AACA,IAAA,IAAA,OAAA,KAAA,CAAA,gBAAA,KAAA,QAAA,EAAA,KAAA,CAAA,YAAA,GAAA,KAAA,CAAA,gBAAA;AACA,IAAA,IAAA,OAAA,KAAA,CAAA,oBAAA,KAAA,QAAA,EAAA,KAAA,CAAA,gBAAA,GAAA,KAAA,CAAA,oBAAA;AACA,IAAA,IAAA,OAAA,KAAA,CAAA,eAAA,KAAA,QAAA,EAAA,KAAA,CAAA,WAAA,GAAA,KAAA,CAAA,eAAA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAA,sBAAA,CAAA,KAAA,EAAA,KAAA,EAAA,aAAA,EAAA;AACA,EAAA,IAAA,KAAA,CAAA,OAAA,CAAA,KAAA,CAAA,aAAA,CAAA,EAAA;AACA,IAAA,KAAA,CAAA,SAAA,CAAA,IAAA,CAAA,GAAA,KAAA,CAAA,aAAA,CAAA;AACA;;AAEA,EAAA,KAAA,MAAA,SAAA,IAAA,KAAA,CAAA,UAAA,IAAA,EAAA,EAAA;AACA,IAAA,IAAA,SAAA,EAAA,YAAA,IAAA,CAAA,KAAA,CAAA,aAAA,CAAA,QAAA,CAAA,SAAA,CAAA,YAAA,CAAA,EAAA;AACA,MAAA,KAAA,CAAA,aAAA,CAAA,IAAA,CAAA,SAAA,CAAA,YAAA,CAAA;AACA;;AAEA,IAAA,KAAA,MAAA,IAAA,IAAA,SAAA,EAAA,OAAA,EAAA,KAAA,IAAA,EAAA,EAAA;AACA,MAAA,IAAA,aAAA,IAAA,IAAA,CAAA,IAAA,EAAA,KAAA,CAAA,aAAA,CAAA,IAAA,CAAA,IAAA,CAAA,IAAA,CAAA;AACA,MAAA,IAAA,IAAA,CAAA,YAAA,EAAA;AACA,QAAA,KAAA,CAAA,SAAA,CAAA,IAAA,CAAA;AACA,UAAA,IAAA,EAAA,UAAA;AACA,UAAA,EAAA,EAAA,IAAA,CAAA,YAAA,CAAA,EAAA;AACA,UAAA,IAAA,EAAA,IAAA,CAAA,YAAA,CAAA,IAAA;AACA,UAAA,SAAA,EAAA,IAAA,CAAA,YAAA,CAAA,IAAA;AACA,SAAA,CAAA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAA,YAAA,CAAA,KAAA,EAAA,KAAA,EAAA,aAAA,EAAA,IAAA,EAAA;AACA,EAAA,IAAA,CAAA,KAAA,IAAA,YAAA,CAAA,KAAA,EAAA,IAAA,CAAA,EAAA;AACA,EAAA,sBAAA,CAAA,KAAA,EAAA,KAAA,CAAA;AACA,EAAA,sBAAA,CAAA,KAAA,EAAA,KAAA,EAAA,aAAA,CAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,gBAAA,gBAAA;AACA,EAAA,MAAA;AACA,EAAA,IAAA;AACA,EAAA,aAAA;AACA,EAAA;AACA,EAAA,MAAA,KAAA,GAAA;AACA,IAAA,aAAA,EAAA,EAAA;AACA,IAAA,aAAA,EAAA,EAAA;AACA,IAAA,SAAA,EAAA,EAAA;AACA,GAAA;;AAEA,EAAA,IAAA;AACA,IAAA,WAAA,MAAA,KAAA,IAAA,MAAA,EAAA;AACA,MAAA,YAAA,CAAA,KAAA,EAAA,KAAA,EAAA,aAAA,EAAA,IAAA,CAAA;AACA,MAAA,MAAA,KAAA;AACA;AACA,GAAA,SAAA;AACA,IAAA,MAAA,KAAA,GAAA;AACA,MAAA,CAAA,mCAAA,GAAA,IAAA;AACA,KAAA;;AAEA,IAAA,IAAA,KAAA,CAAA,UAAA,EAAA,KAAA,CAAA,4BAAA,CAAA,GAAA,KAAA,CAAA,UAAA;AACA,IAAA,IAAA,KAAA,CAAA,aAAA,EAAA,KAAA,CAAA,+BAAA,CAAA,GAAA,KAAA,CAAA,aAAA;AACA,IAAA,IAAA,KAAA,CAAA,YAAA,KAAA,SAAA,EAAA,KAAA,CAAA,mCAAA,CAAA,GAAA,KAAA,CAAA,YAAA;AACA,IAAA,IAAA,KAAA,CAAA,gBAAA,KAAA,SAAA,EAAA,KAAA,CAAA,oCAAA,CAAA,GAAA,KAAA,CAAA,gBAAA;AACA,IAAA,IAAA,KAAA,CAAA,WAAA,KAAA,SAAA,EAAA,KAAA,CAAA,mCAAA,CAAA,GAAA,KAAA,CAAA,WAAA;;AAEA,IAAA,IAAA,KAAA,CAAA,aAAA,CAAA,MAAA,EAAA;AACA,MAAA,KAAA,CAAA,wCAAA,CAAA,GAAA,IAAA,CAAA,SAAA,CAAA,KAAA,CAAA,aAAA,CAAA;AACA;AACA,IAAA,IAAA,aAAA,IAAA,KAAA,CAAA,aAAA,CAAA,MAAA,EAAA;AACA,MAAA,KAAA,CAAA,8BAAA,CAAA,GAAA,KAAA,CAAA,aAAA,CAAA,IAAA,CAAA,EAAA,CAAA;AACA;AACA,IAAA,IAAA,aAAA,IAAA,KAAA,CAAA,SAAA,CAAA,MAAA,EAAA;AACA,MAAA,KAAA,CAAA,oCAAA,CAAA,GAAA,IAAA,CAAA,SAAA,CAAA,KAAA,CAAA,SAAA,CAAA;AACA;;AAEA,IAAA,IAAA,CAAA,aAAA,CAAA,KAAA,CAAA;AACA,IAAA,IAAA,CAAA,GAAA,EAAA;AACA;AACA;;;;"}